{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([_IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='vendor_id', vocabulary_list=(1, 2), dtype=tf.int32, default_value=-1)), _EmbeddingColumn(categorical_column=_CrossedColumn(keys=(_BucketizedColumn(source_column=_NumericColumn(key='pickup_latitude', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None), boundaries=(40.700000000000003, 40.702750000000002, 40.705500000000001, 40.70825, 40.710999999999999, 40.713749999999997, 40.716499999999996, 40.719249999999995, 40.721999999999994, 40.724749999999993, 40.727499999999992, 40.730249999999991, 40.73299999999999, 40.735749999999989, 40.738499999999988, 40.741249999999987, 40.743999999999986, 40.746749999999984, 40.749499999999983, 40.752249999999982, 40.754999999999981, 40.75774999999998, 40.760499999999979, 40.763249999999978, 40.765999999999977, 40.768749999999976, 40.771499999999975, 40.774249999999974, 40.776999999999973, 40.779749999999972, 40.78249999999997, 40.785249999999969, 40.787999999999968, 40.790749999999967, 40.793499999999966, 40.796249999999965, 40.798999999999964, 40.801749999999963, 40.804499999999962, 40.807249999999961)), _BucketizedColumn(source_column=_NumericColumn(key='pickup_longitude', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None), boundaries=(-74.0, -73.993750000000006, -73.987500000000011, -73.981250000000017, -73.975000000000023, -73.968750000000028, -73.962500000000034, -73.95625000000004, -73.950000000000045, -73.943750000000051, -73.937500000000057, -73.931250000000063, -73.925000000000068, -73.918750000000074, -73.91250000000008, -73.906250000000085, -73.900000000000091, -73.893750000000097, -73.887500000000102, -73.881250000000108, -73.875000000000114, -73.868750000000119, -73.862500000000125, -73.856250000000131, -73.850000000000136, -73.843750000000142, -73.837500000000148, -73.831250000000153, -73.825000000000159, -73.818750000000165, -73.812500000000171, -73.806250000000176, -73.800000000000182, -73.793750000000188, -73.787500000000193, -73.781250000000199, -73.775000000000205, -73.76875000000021, -73.762500000000216, -73.756250000000222))), hash_bucket_size=400, hash_key=None), dimension=20, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x120e760d0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='weekday', vocabulary_list=(0, 1, 2, 3, 4, 5), dtype=tf.int32, default_value=-1)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='week_of_the_year', vocabulary_list=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51), dtype=tf.int32, default_value=-1)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='hour', vocabulary_list=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22), dtype=tf.int32, default_value=-1)), _NumericColumn(key='distance', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/raghr010/anaconda/envs/tensorflow/lib/python2.7/site-packages/')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "\n",
    "MIN_LAT=40.7\n",
    "MAX_LAT=40.81\n",
    "MIN_LONG=-74\n",
    "MAX_LONG=-73.75\n",
    "LAT_BUCKETS=40\n",
    "LONG_BUCKETS=40\n",
    "BATCH_SIZE = 2000\n",
    "TRAIN_EPOCHS = 400\n",
    "\n",
    "TEST_EPOCHS = 1\n",
    "TEST_EXAMPLE_SIZE=20\n",
    "\n",
    "columns = {'vendor_id' : 0,\n",
    "        'passenger_count' :1,\n",
    "        'pickup_longitude' : 2,\n",
    "        'pickup_latitude' : 3,\n",
    "        'dropoff_longitude' : 4,\n",
    "        'dropoff_latitude' : 5,\n",
    "        'store_and_fwd_flag' : 6,\n",
    "        'trip_duration' : 7,\n",
    "        'month' : 8,\n",
    "        'date' : 9,\n",
    "        'hour' : 10,\n",
    "        'weekday' : 11,\n",
    "        'week_of_the_year' : 12,\n",
    "          'distance' : 13}\n",
    "\n",
    "def normalize_column(col):\n",
    "    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "float_columns = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "\n",
    "# Real valued columns\n",
    "#passenger_count    = tf.feature_column.indicator_column(normalize_column(tf.feature_column.numeric_column(\"passenger_count\", dtype=tf.int32)))\n",
    "\n",
    "# Create 20 bins for latitude, logitude and create 2 embedding column\n",
    "pickup_latitude = tf.feature_column.numeric_column(\"pickup_latitude\", dtype=tf.float64)\n",
    "pickup_latitude_feature = tf.feature_column.bucketized_column(\n",
    "    source_column=pickup_latitude,boundaries = list(np.arange( MIN_LAT, MAX_LAT, (MAX_LAT-MIN_LAT)/LAT_BUCKETS)))\n",
    "\n",
    "pickup_longitude = tf.feature_column.numeric_column(\"pickup_longitude\", dtype=tf.float64 )\n",
    "pickup_longitude_feature = tf.feature_column.bucketized_column(\n",
    "    source_column=pickup_longitude,boundaries = list(np.arange(MIN_LONG, MAX_LONG, (MAX_LONG-MIN_LONG)/LAT_BUCKETS)))\n",
    "\n",
    "\n",
    "dropoff_latitude = tf.feature_column.numeric_column(\"dropoff_latitude\", dtype=tf.float64)\n",
    "dropoff_latitude_feature = tf.feature_column.bucketized_column(\n",
    "    source_column=dropoff_latitude,boundaries = list(np.arange( MIN_LAT, MAX_LAT, (MAX_LAT-MIN_LAT)/LAT_BUCKETS)))\n",
    "\n",
    "dropoff_longitude = tf.feature_column.numeric_column(\"dropoff_longitude\", dtype=tf.float64)\n",
    "dropoff_longitude_feature = tf.feature_column.bucketized_column(\n",
    "    source_column=dropoff_longitude,boundaries = list(np.arange(MIN_LONG, MAX_LONG, (MAX_LONG-MIN_LONG)/LAT_BUCKETS)))\n",
    "\n",
    "\n",
    "distance = tf.feature_column.numeric_column(\"distance\", dtype=tf.float64)\n",
    "\n",
    "pickup_lat_x_long = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.crossed_column(\n",
    "        keys=[pickup_latitude_feature, pickup_longitude_feature],\n",
    "        hash_bucket_size=400\n",
    "    ),\n",
    "    dimension=20\n",
    ")\n",
    "\n",
    "\n",
    "# Direct columns from file\n",
    "vendor = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('vendor_id', [1,2], dtype=tf.int32))\n",
    "\n",
    "store_and_fwd_flag =tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('store_and_fwd_flag', [1,0], dtype=tf.int32))\n",
    "\n",
    "# Date columns\n",
    "month = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('month', range(1,12), dtype=tf.int32))\n",
    "date = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('date', range(1,31), dtype=tf.int32))\n",
    "hour = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('hour', range(0,23), dtype=tf.int32))\n",
    "\n",
    "\n",
    "weekday = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('weekday', range(0,6), dtype=tf.int32))\n",
    "week_of_the_year = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('week_of_the_year', range(1,52), dtype=tf.int32))\n",
    "\n",
    "# month_date_hour = tf.feature_column.indicator_column(\n",
    "#     tf.feature_column.crossed_column(\n",
    "#         keys=[month, date, hour],\n",
    "#         hash_bucket_size=8928\n",
    "#     )\n",
    "# )\n",
    "#\n",
    "# weekday_hour = tf.feature_column.indicator_column(\n",
    "#     tf.feature_column.crossed_column(\n",
    "#         keys=[weekday, hour],\n",
    "#         hash_bucket_size=364\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "feature_columns = { pickup_lat_x_long,\n",
    "                   vendor, weekday, hour, week_of_the_year, week_of_the_year, distance}\n",
    "\n",
    "print feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_frame(file_name, predict=False):\n",
    "    df = pd.read_csv(file_name, header=0)\n",
    "\n",
    "    def pickup_weekday(row):\n",
    "        return datetime.date(int(row['year']), int(row['month']), int(row['date'])).weekday()\n",
    "\n",
    "    def week_of_year(row):\n",
    "        return datetime.date(int(row['year']), int(row['month']), int(row['date'])).isocalendar()[1]\n",
    "\n",
    "    def store_and_forward(row):\n",
    "        return 1 if row['store_and_fwd_flag'] == 'Y' else 0\n",
    "    \n",
    "    def distance(row):\n",
    "        a = (row['pickup_latitude'], row['pickup_longitude'])\n",
    "        b = (row['dropoff_latitude'], row['dropoff_longitude'])\n",
    "        return (vincenty(a, b).miles)\n",
    "\n",
    "    df['month'] = df['pickup_datetime'].str.split('-').str[1].astype(np.int32)\n",
    "    df['year'] = df['pickup_datetime'].str.split('-').str[0].astype(np.int32)\n",
    "    df['date'] = df['pickup_datetime'].str.split('-').str[2].str.split(' ').str[0].astype(np.int32).astype(np.int32)\n",
    "    df['hour'] = df['pickup_datetime'].str.split(' ').str[1].str.split(':').str[0].astype(np.int32)\n",
    "    df['store_and_fwd_flag'] = df.apply(store_and_forward, axis=1).astype(np.int32)\n",
    "    df['weekday'] = df.apply(pickup_weekday, axis=1).astype(np.int32)\n",
    "\n",
    "    df['week_of_the_year'] = df.apply(week_of_year, axis=1).astype(np.int32)\n",
    "    df['distance'] = normalize_column(df.apply(distance, axis=1).astype(np.float64))\n",
    "    \n",
    "    del df['pickup_datetime']\n",
    "    if not predict:\n",
    "        del df['dropoff_datetime']\n",
    "\n",
    "    del df['year']\n",
    "\n",
    "    del df['id']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training_and_test_data(file_name):\n",
    "\n",
    "    df = get_data_frame(file_name)\n",
    "\n",
    "    np.random.shuffle(df.values)\n",
    "\n",
    "    df_train = df[: -1 * TEST_EXAMPLE_SIZE]\n",
    "\n",
    "    df_test = df[-1 * TEST_EXAMPLE_SIZE:]\n",
    "\n",
    "    df_train.to_pickle('training_data.npy')\n",
    "    df_test.to_pickle('testing_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_prediction_data(file_name):\n",
    "    df = get_data_frame(file_name, predict=True)\n",
    "    df['trip_duration'] = np.ones(len(df))\n",
    "    print 'DF', len(df.values)\n",
    "    df.to_pickle('predict_data.npy')\n",
    "\n",
    "\n",
    "def normalize_column(col):\n",
    "    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "\n",
    "def make_input_fn(test=False, predict=False):\n",
    "\n",
    "    if predict:\n",
    "        df = pd.read_pickle('predict_data.npy')\n",
    "    else:\n",
    "        df = pd.read_pickle('training_data.npy') if not test else pd.read_pickle('testing_data.npy')\n",
    "\n",
    "    EPOCHS = TRAIN_EPOCHS if not test else TEST_EPOCHS\n",
    "    if predict:\n",
    "        EPOCHS = TEST_EPOCHS\n",
    "\n",
    "    df = df.values\n",
    "\n",
    "    x = {}\n",
    "    for column in columns:\n",
    "        if column not in float_columns:\n",
    "            x[column] = df[:, columns[column]].astype(np.int32)\n",
    "        else:\n",
    "            x[column] = df[:, columns[column]].astype(np.float64)\n",
    "\n",
    "    if not predict:\n",
    "        input_fn = tf.contrib.learn.io.numpy_input_fn(\n",
    "\n",
    "            x=x,\n",
    "            y=normalize_column(df[:, columns['trip_duration']]),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_epochs=EPOCHS,\n",
    "        )\n",
    "    else:\n",
    "        print x\n",
    "        input_fn = tf.contrib.learn.io.numpy_input_fn(\n",
    "\n",
    "            x=x,\n",
    "            batch_size=len(x),\n",
    "            num_epochs=1,\n",
    "        )\n",
    "\n",
    "    return input_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13bad1c50>, '_model_dir': './models/', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):\n",
      "<tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "['File \"/Users/raghr010/anaconda/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\\n    \"__main__\", fname, loader, pkg_name)', 'File \"/Users/raghr010/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\\n    exec code in run_globals', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\\n    app.launch_new_instance()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\\n    app.start()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\\n    ioloop.IOLoop.instance().start()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\\n    super(ZMQIOLoop, self).start()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\\n    handler_func(fd_obj, events)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\\n    self._handle_recv()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\\n    self._run_callback(callback, msg)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\\n    callback(*args, **kwargs)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\\n    return self.dispatch_shell(stream, msg)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\\n    handler(stream, idents, msg)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\\n    user_expressions, allow_stdin)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\\n    interactivity=interactivity, compiler=compiler, result=result)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\\n    if self.run_code(code, result):', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)', u'File \"<ipython-input-6-423eb3170885>\", line 14, in <module>\\n    estimator.fit(input_fn=make_input_fn())', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\\n    return func(*args, **kwargs)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 455, in fit\\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1003, in _train_model\\n    config=self._session_config', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 352, in MonitoredTrainingSession\\n    stop_grace_period_secs=stop_grace_period_secs)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 648, in __init__\\n    stop_grace_period_secs=stop_grace_period_secs)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 477, in __init__\\n    self._sess = _RecoverableSession(self._coordinated_creator)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 822, in __init__\\n    _WrappedSession.__init__(self, self._create_session())', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in _create_session\\n    return self._sess_creator.create_session()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 538, in create_session\\n    self.tf_sess = self._session_creator.create_session()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 403, in create_session\\n    self._scaffold.finalize()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 192, in finalize\\n    default_ready_for_local_init_op)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 254, in get_or_default\\n    op = default_constructor()', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 189, in default_ready_for_local_init_op\\n    variables.global_variables())', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 170, in wrapped\\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 139, in _add_should_use_warning\\n    wrapped = TFShouldUseWarningWrapper(x)', 'File \"/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 96, in __init__\\n    stack = [s.strip() for s in traceback.format_stack()]']\n",
      "==================================\n",
      "WARNING:tensorflow:From /Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./models/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.427733, step = 1\n",
      "INFO:tensorflow:global_step/sec: 16.6617\n",
      "INFO:tensorflow:loss = 0.164071, step = 101 (6.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9961\n",
      "INFO:tensorflow:loss = 0.68514, step = 201 (5.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0805\n",
      "INFO:tensorflow:loss = 0.161053, step = 301 (5.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1196\n",
      "INFO:tensorflow:loss = 0.294763, step = 401 (5.841 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 17.3102\n",
      "INFO:tensorflow:loss = 0.557786, step = 501 (5.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9965\n",
      "INFO:tensorflow:loss = 0.163238, step = 601 (5.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8731\n",
      "INFO:tensorflow:loss = 0.822544, step = 701 (5.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9479\n",
      "INFO:tensorflow:loss = 0.430515, step = 801 (5.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2528\n",
      "INFO:tensorflow:loss = 0.295864, step = 901 (5.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9678\n",
      "INFO:tensorflow:loss = 0.560151, step = 1001 (5.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0048\n",
      "INFO:tensorflow:loss = 0.423784, step = 1101 (5.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0031\n",
      "INFO:tensorflow:loss = 0.294461, step = 1201 (5.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2876\n",
      "INFO:tensorflow:loss = 0.1638, step = 1301 (5.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7636\n",
      "INFO:tensorflow:loss = 0.553875, step = 1401 (5.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8008\n",
      "INFO:tensorflow:loss = 0.708201, step = 1501 (5.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6394\n",
      "INFO:tensorflow:loss = 0.293655, step = 1601 (5.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8778\n",
      "INFO:tensorflow:loss = 0.285629, step = 1701 (5.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9111\n",
      "INFO:tensorflow:loss = 0.160893, step = 1801 (5.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0037\n",
      "INFO:tensorflow:loss = 0.287727, step = 1901 (5.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0487\n",
      "INFO:tensorflow:loss = 0.422619, step = 2001 (5.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1116\n",
      "INFO:tensorflow:loss = 0.183627, step = 2101 (5.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9376\n",
      "INFO:tensorflow:loss = 0.158684, step = 2201 (5.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8026\n",
      "INFO:tensorflow:loss = 0.42652, step = 2301 (5.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9546\n",
      "INFO:tensorflow:loss = 0.289505, step = 2401 (5.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1526\n",
      "INFO:tensorflow:loss = 0.637303, step = 2501 (5.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1466\n",
      "INFO:tensorflow:loss = 0.55384, step = 2601 (5.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0119\n",
      "INFO:tensorflow:loss = 0.827092, step = 2701 (5.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0511\n",
      "INFO:tensorflow:loss = 0.154352, step = 2801 (5.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0421\n",
      "INFO:tensorflow:loss = 0.294541, step = 2901 (5.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2023\n",
      "INFO:tensorflow:loss = 0.29073, step = 3001 (5.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0285\n",
      "INFO:tensorflow:loss = 0.152301, step = 3101 (5.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7639\n",
      "INFO:tensorflow:loss = 0.56662, step = 3201 (5.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0351\n",
      "INFO:tensorflow:loss = 0.290904, step = 3301 (5.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1715\n",
      "INFO:tensorflow:loss = 0.167171, step = 3401 (5.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.055\n",
      "INFO:tensorflow:loss = 0.345767, step = 3501 (5.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5966\n",
      "INFO:tensorflow:loss = 0.546531, step = 3601 (6.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5031\n",
      "INFO:tensorflow:loss = 0.282746, step = 3701 (6.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9172\n",
      "INFO:tensorflow:loss = 0.0233583, step = 3801 (5.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8179\n",
      "INFO:tensorflow:loss = 0.549317, step = 3901 (5.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8086\n",
      "INFO:tensorflow:loss = 0.166295, step = 4001 (5.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7991\n",
      "INFO:tensorflow:loss = 0.154039, step = 4101 (5.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6776\n",
      "INFO:tensorflow:loss = 0.545486, step = 4201 (5.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6224\n",
      "INFO:tensorflow:loss = 0.418283, step = 4301 (6.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7817\n",
      "INFO:tensorflow:loss = 0.225251, step = 4401 (5.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8184\n",
      "INFO:tensorflow:loss = 0.140616, step = 4501 (5.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9406\n",
      "INFO:tensorflow:loss = 0.538933, step = 4601 (5.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9259\n",
      "INFO:tensorflow:loss = 0.280607, step = 4701 (5.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0092\n",
      "INFO:tensorflow:loss = 0.290642, step = 4801 (5.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9701\n",
      "INFO:tensorflow:loss = 0.426432, step = 4901 (5.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9835\n",
      "INFO:tensorflow:loss = 0.287467, step = 5001 (5.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8949\n",
      "INFO:tensorflow:loss = 0.402691, step = 5101 (5.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0236\n",
      "INFO:tensorflow:loss = 0.419894, step = 5201 (5.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0716\n",
      "INFO:tensorflow:loss = 0.155728, step = 5301 (5.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1537\n",
      "INFO:tensorflow:loss = 0.156366, step = 5401 (5.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0983\n",
      "INFO:tensorflow:loss = 0.836387, step = 5501 (5.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0318\n",
      "INFO:tensorflow:loss = 0.54981, step = 5601 (5.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2304\n",
      "INFO:tensorflow:loss = 0.512128, step = 5701 (5.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5379\n",
      "INFO:tensorflow:loss = 0.551894, step = 5801 (5.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5039\n",
      "INFO:tensorflow:loss = 0.407764, step = 5901 (5.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2829\n",
      "INFO:tensorflow:loss = 0.412876, step = 6001 (5.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5556\n",
      "INFO:tensorflow:loss = 0.418193, step = 6101 (5.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2401\n",
      "INFO:tensorflow:loss = 0.544752, step = 6201 (6.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3132\n",
      "INFO:tensorflow:loss = 0.393541, step = 6301 (6.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4521\n",
      "INFO:tensorflow:loss = 0.0210605, step = 6401 (6.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6078\n",
      "INFO:tensorflow:loss = 0.783016, step = 6501 (6.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3064\n",
      "INFO:tensorflow:loss = 0.416366, step = 6601 (6.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3793\n",
      "INFO:tensorflow:loss = 0.0877132, step = 6701 (6.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7155\n",
      "INFO:tensorflow:loss = 0.872501, step = 6801 (5.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7304\n",
      "INFO:tensorflow:loss = 0.287889, step = 6901 (5.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6392\n",
      "INFO:tensorflow:loss = 0.286902, step = 7001 (6.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6591\n",
      "INFO:tensorflow:loss = 0.555944, step = 7101 (6.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6737\n",
      "INFO:tensorflow:loss = 0.44802, step = 7201 (5.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6267\n",
      "INFO:tensorflow:loss = 0.838299, step = 7301 (6.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6706\n",
      "INFO:tensorflow:loss = 0.0193834, step = 7401 (5.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.766\n",
      "INFO:tensorflow:loss = 0.423364, step = 7501 (5.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.926\n",
      "INFO:tensorflow:loss = 0.808898, step = 7601 (5.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9321\n",
      "INFO:tensorflow:loss = 0.287256, step = 7701 (5.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.046\n",
      "INFO:tensorflow:loss = 0.545341, step = 7801 (5.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4056\n",
      "INFO:tensorflow:loss = 0.554082, step = 7901 (6.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9674\n",
      "INFO:tensorflow:loss = 0.285621, step = 8001 (5.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7088\n",
      "INFO:tensorflow:loss = 0.02233, step = 8101 (5.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6865\n",
      "INFO:tensorflow:loss = 0.559551, step = 8201 (5.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9645\n",
      "INFO:tensorflow:loss = 0.268597, step = 8301 (5.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5072\n",
      "INFO:tensorflow:loss = 0.814893, step = 8401 (6.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8943\n",
      "INFO:tensorflow:loss = 0.284807, step = 8501 (5.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5541\n",
      "INFO:tensorflow:loss = 0.280514, step = 8601 (6.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8522\n",
      "INFO:tensorflow:loss = 0.417813, step = 8701 (5.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.773\n",
      "INFO:tensorflow:loss = 0.139908, step = 8801 (5.961 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 17.1178\n",
      "INFO:tensorflow:loss = 0.0196288, step = 8901 (5.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8815\n",
      "INFO:tensorflow:loss = 68.7931, step = 9001 (5.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8934\n",
      "INFO:tensorflow:loss = 0.273666, step = 9101 (5.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1132\n",
      "INFO:tensorflow:loss = 0.30336, step = 9201 (5.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6241\n",
      "INFO:tensorflow:loss = 0.411016, step = 9301 (6.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7443\n",
      "INFO:tensorflow:loss = 0.151659, step = 9401 (5.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8046\n",
      "INFO:tensorflow:loss = 0.280492, step = 9501 (5.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8274\n",
      "INFO:tensorflow:loss = 0.136279, step = 9601 (5.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9322\n",
      "INFO:tensorflow:loss = 0.666296, step = 9701 (5.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7218\n",
      "INFO:tensorflow:loss = 0.283519, step = 9801 (5.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3007\n",
      "INFO:tensorflow:loss = 0.408764, step = 9901 (6.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.224\n",
      "INFO:tensorflow:loss = 0.15495, step = 10001 (6.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5297\n",
      "INFO:tensorflow:loss = 0.416435, step = 10101 (6.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4626\n",
      "INFO:tensorflow:loss = 0.571089, step = 10201 (6.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8699\n",
      "INFO:tensorflow:loss = 0.285033, step = 10301 (6.301 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10315 into ./models/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.2358\n",
      "INFO:tensorflow:loss = 0.412858, step = 10401 (7.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7371\n",
      "INFO:tensorflow:loss = 0.813067, step = 10501 (6.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3171\n",
      "INFO:tensorflow:loss = 0.151638, step = 10601 (6.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3658\n",
      "INFO:tensorflow:loss = 0.951522, step = 10701 (6.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5264\n",
      "INFO:tensorflow:loss = 0.281103, step = 10801 (6.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.309\n",
      "INFO:tensorflow:loss = 0.160362, step = 10901 (6.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2589\n",
      "INFO:tensorflow:loss = 1.07143, step = 11001 (6.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5439\n",
      "INFO:tensorflow:loss = 0.396579, step = 11101 (6.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2227\n",
      "INFO:tensorflow:loss = 0.381123, step = 11201 (6.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2696\n",
      "INFO:tensorflow:loss = 0.279942, step = 11301 (6.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6364\n",
      "INFO:tensorflow:loss = 0.548844, step = 11401 (6.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.901\n",
      "INFO:tensorflow:loss = 226.757, step = 11501 (6.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2295\n",
      "INFO:tensorflow:loss = 0.276702, step = 11601 (6.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6008\n",
      "INFO:tensorflow:loss = 0.4328, step = 11701 (6.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6955\n",
      "INFO:tensorflow:loss = 0.940831, step = 11801 (6.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7851\n",
      "INFO:tensorflow:loss = 0.416266, step = 11901 (7.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4017\n",
      "INFO:tensorflow:loss = 0.276252, step = 12001 (6.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6542\n",
      "INFO:tensorflow:loss = 0.840699, step = 12101 (6.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9454\n",
      "INFO:tensorflow:loss = 0.409215, step = 12201 (6.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4366\n",
      "INFO:tensorflow:loss = 0.411501, step = 12301 (6.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5961\n",
      "INFO:tensorflow:loss = 0.284773, step = 12401 (6.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5466\n",
      "INFO:tensorflow:loss = 0.14937, step = 12501 (6.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4881\n",
      "INFO:tensorflow:loss = 0.289712, step = 12601 (5.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6396\n",
      "INFO:tensorflow:loss = 1.06962, step = 12701 (5.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.733\n",
      "INFO:tensorflow:loss = 0.147319, step = 12801 (5.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9681\n",
      "INFO:tensorflow:loss = 0.679103, step = 12901 (5.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0561\n",
      "INFO:tensorflow:loss = 0.15253, step = 13001 (5.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0915\n",
      "INFO:tensorflow:loss = 0.406169, step = 13101 (5.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0726\n",
      "INFO:tensorflow:loss = 0.152986, step = 13201 (5.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1201\n",
      "INFO:tensorflow:loss = 0.282489, step = 13301 (5.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.911\n",
      "INFO:tensorflow:loss = 0.283487, step = 13401 (5.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0182\n",
      "INFO:tensorflow:loss = 0.410026, step = 13501 (5.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2644\n",
      "INFO:tensorflow:loss = 0.293729, step = 13601 (5.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9591\n",
      "INFO:tensorflow:loss = 0.148552, step = 13701 (5.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.88\n",
      "INFO:tensorflow:loss = 0.406615, step = 13801 (6.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8366\n",
      "INFO:tensorflow:loss = 0.291417, step = 13901 (6.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0449\n",
      "INFO:tensorflow:loss = 0.417435, step = 14001 (5.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7569\n",
      "INFO:tensorflow:loss = 0.312936, step = 14101 (5.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6006\n",
      "INFO:tensorflow:loss = 0.323053, step = 14201 (5.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2833\n",
      "INFO:tensorflow:loss = 0.613396, step = 14301 (5.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0249\n",
      "INFO:tensorflow:loss = 0.346683, step = 14401 (7.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6984\n",
      "INFO:tensorflow:loss = 0.680828, step = 14501 (5.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8698\n",
      "INFO:tensorflow:loss = 0.0170638, step = 14601 (5.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7354\n",
      "INFO:tensorflow:loss = 0.410825, step = 14701 (5.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.769\n",
      "INFO:tensorflow:loss = 0.410588, step = 14801 (5.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3864\n",
      "INFO:tensorflow:loss = 0.35607, step = 14901 (5.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2425\n",
      "INFO:tensorflow:loss = 0.407179, step = 15001 (5.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7784\n",
      "INFO:tensorflow:loss = 0.42879, step = 15101 (5.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8599\n",
      "INFO:tensorflow:loss = 0.404355, step = 15201 (5.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9015\n",
      "INFO:tensorflow:loss = 0.415145, step = 15301 (5.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9153\n",
      "INFO:tensorflow:loss = 0.798559, step = 15401 (5.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8757\n",
      "INFO:tensorflow:loss = 0.72289, step = 15501 (5.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8162\n",
      "INFO:tensorflow:loss = 0.0620948, step = 15601 (5.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8043\n",
      "INFO:tensorflow:loss = 0.150224, step = 15701 (5.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0389\n",
      "INFO:tensorflow:loss = 0.548835, step = 15801 (5.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7803\n",
      "INFO:tensorflow:loss = 0.525783, step = 15901 (5.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9118\n",
      "INFO:tensorflow:loss = 0.149676, step = 16001 (5.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8769\n",
      "INFO:tensorflow:loss = 0.334371, step = 16101 (5.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9837\n",
      "INFO:tensorflow:loss = 0.53988, step = 16201 (5.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.787\n",
      "INFO:tensorflow:loss = 0.694276, step = 16301 (5.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9648\n",
      "INFO:tensorflow:loss = 0.145613, step = 16401 (5.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8856\n",
      "INFO:tensorflow:loss = 0.390484, step = 16501 (5.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7683\n",
      "INFO:tensorflow:loss = 0.526908, step = 16601 (5.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9307\n",
      "INFO:tensorflow:loss = 0.415073, step = 16701 (5.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9315\n",
      "INFO:tensorflow:loss = 0.283502, step = 16801 (5.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9537\n",
      "INFO:tensorflow:loss = 0.537849, step = 16901 (5.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9117\n",
      "INFO:tensorflow:loss = 0.404461, step = 17001 (5.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.149862, step = 17101 (5.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9683\n",
      "INFO:tensorflow:loss = 0.645971, step = 17201 (5.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0347\n",
      "INFO:tensorflow:loss = 0.685061, step = 17301 (5.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9963\n",
      "INFO:tensorflow:loss = 0.540562, step = 17401 (5.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8628\n",
      "INFO:tensorflow:loss = 0.281857, step = 17501 (5.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0481\n",
      "INFO:tensorflow:loss = 0.282758, step = 17601 (5.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7814\n",
      "INFO:tensorflow:loss = 0.4164, step = 17701 (5.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8211\n",
      "INFO:tensorflow:loss = 0.0169011, step = 17801 (5.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9229\n",
      "INFO:tensorflow:loss = 0.148997, step = 17901 (5.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8122\n",
      "INFO:tensorflow:loss = 0.800801, step = 18001 (5.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5277\n",
      "INFO:tensorflow:loss = 0.0162161, step = 18101 (5.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8871\n",
      "INFO:tensorflow:loss = 0.0153989, step = 18201 (5.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2627\n",
      "INFO:tensorflow:loss = 0.414182, step = 18301 (5.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5707\n",
      "INFO:tensorflow:loss = 0.406766, step = 18401 (5.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5046\n",
      "INFO:tensorflow:loss = 0.271432, step = 18501 (5.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.818\n",
      "INFO:tensorflow:loss = 0.215417, step = 18601 (5.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9913\n",
      "INFO:tensorflow:loss = 0.492343, step = 18701 (5.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.845\n",
      "INFO:tensorflow:loss = 0.416492, step = 18801 (5.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9025\n",
      "INFO:tensorflow:loss = 0.399816, step = 18901 (5.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9518\n",
      "INFO:tensorflow:loss = 0.145727, step = 19001 (5.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.528\n",
      "INFO:tensorflow:loss = 0.412839, step = 19101 (5.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2058\n",
      "INFO:tensorflow:loss = 0.414333, step = 19201 (6.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3596\n",
      "INFO:tensorflow:loss = 0.413243, step = 19301 (5.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7508\n",
      "INFO:tensorflow:loss = 0.283944, step = 19401 (5.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9686\n",
      "INFO:tensorflow:loss = 0.404809, step = 19501 (5.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9317\n",
      "INFO:tensorflow:loss = 0.0163372, step = 19601 (5.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9141\n",
      "INFO:tensorflow:loss = 0.416624, step = 19701 (5.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8545\n",
      "INFO:tensorflow:loss = 0.530977, step = 19801 (5.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1603\n",
      "INFO:tensorflow:loss = 0.413413, step = 19901 (5.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2861\n",
      "INFO:tensorflow:loss = 0.410333, step = 20001 (5.469 sec)\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.contrib.learn.DNNRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[512, 128, 16],\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=0.00001,\n",
    "      l1_regularization_strength=0.001\n",
    "    ),\n",
    "model_dir=\"./models/\")\n",
    "\n",
    "\n",
    "#create_training_and_test_data('train.csv')\n",
    "#create_prediction_data('test.csv')\n",
    "\n",
    "estimator.fit(input_fn=make_input_fn())\n",
    "\n",
    "print estimator.evaluate(input_fn=make_input_fn(test=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625134\n",
      "{'distance': array([1, 1, 1, ..., 1, 1, 1], dtype=int32), 'week_of_the_year': array([0, 0, 0, ..., 1, 3, 0], dtype=int32), 'hour': array([3, 3, 3, ..., 4, 4, 4], dtype=int32), 'trip_duration': array([6, 6, 6, ..., 1, 1, 1], dtype=int32), 'vendor_id': array([1, 1, 1, ..., 1, 1, 2], dtype=int32), 'pickup_longitude': array([-73.98812866, -73.96420288, -73.99743652, ..., -73.97226715,\n",
      "       -73.97650146, -73.98184967]), 'month': array([30, 30, 30, ...,  1,  1,  1], dtype=int32), 'dropoff_longitude': array([-73.99017334, -73.95980835, -73.98616028, ..., -73.87660217,\n",
      "       -73.85426331, -73.96932983]), 'passenger_count': array([1, 1, 1, ..., 2, 1, 2], dtype=int32), 'weekday': array([26, 26, 26, ..., 53, 53, 53], dtype=int32), 'date': array([23, 23, 23, ...,  0,  0,  0], dtype=int32), 'store_and_fwd_flag': array([0, 0, 0, ..., 0, 0, 0], dtype=int32), 'pickup_latitude': array([ 40.73202896,  40.67999268,  40.73758316, ...,  40.75986481,\n",
      "        40.73356247,  40.7168808 ]), 'dropoff_latitude': array([ 40.75667953,  40.65540314,  40.72952271, ...,  40.74866486,\n",
      "        40.89178848,  40.76937866])}\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Couldn't find trained model at ./models/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9b64c4edc2c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id,trip_duration\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m               instructions)\n\u001b[0;32m--> 347\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    349\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.pyc\u001b[0m in \u001b[0;36mpredict_scores\u001b[0;34m(self, x, input_fn, batch_size, as_iterable)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    745\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, input_fn, batch_size, outputs, as_iterable)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mfeed_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         as_iterable=as_iterable)\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_variable_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/raghr010/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_infer_model\u001b[0;34m(self, input_fn, feed_fn, outputs, as_iterable, iterate_batches)\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       raise NotFittedError(\"Couldn't find trained model at %s.\"\n\u001b[0;32m--> 878\u001b[0;31m                            % self._model_dir)\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Couldn't find trained model at ./models/."
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "with open('test.csv') as fh:\n",
    "    index = 0\n",
    "    for line in fh:\n",
    "        if index == 0:\n",
    "            index += 1\n",
    "            continue\n",
    "        ids.append(line.split(',')[0])\n",
    "\n",
    "\n",
    "print len(ids)\n",
    "\n",
    "\n",
    "with open('submission.csv', 'w') as fh:\n",
    "    fh.write('id,trip_duration\\n')\n",
    "    index = 0\n",
    "    for prediction in  estimator.predict_scores(input_fn=make_input_fn(predict=True)):\n",
    "        fh.write(ids[index] + ',' + str(prediction) + '\\n')\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
